{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>gender</th>\n",
       "      <th>n_words</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>610399</th>\n",
       "      <td>every latter-day saint should read eugene engl...</td>\n",
       "      <td>male</td>\n",
       "      <td>17</td>\n",
       "      <td>every latter - day saint should read eugene en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450653</th>\n",
       "      <td>today was bored at school .. mr liew and miss ...</td>\n",
       "      <td>male</td>\n",
       "      <td>126</td>\n",
       "      <td>today was bored at school .. mr liew and miss ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82433</th>\n",
       "      <td>sorry about that last outburst...lady green's ...</td>\n",
       "      <td>male</td>\n",
       "      <td>54</td>\n",
       "      <td>sorry about that last outburst ... lady green ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406991</th>\n",
       "      <td>In the words of Tenacious D...we are but men! ...</td>\n",
       "      <td>male</td>\n",
       "      <td>17</td>\n",
       "      <td>in the words of tenacious d ... we are but men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383245</th>\n",
       "      <td>Its Friday the 13th. Is anyone out there super...</td>\n",
       "      <td>female</td>\n",
       "      <td>373</td>\n",
       "      <td>its friday the 13th . is anyone out there supe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624995</th>\n",
       "      <td>I am a girly girl. Even if I'm 41. I never car...</td>\n",
       "      <td>female</td>\n",
       "      <td>93</td>\n",
       "      <td>i am a girly girl . even if i 'm 41 . i never ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462692</th>\n",
       "      <td>The Pros of Being Me 1. My rapier wit 2. My za...</td>\n",
       "      <td>female</td>\n",
       "      <td>106</td>\n",
       "      <td>the pros of being me 1 . my rapier wit 2 . my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255647</th>\n",
       "      <td>HIIII!! QUESTION what is the debate on 2morow ...</td>\n",
       "      <td>male</td>\n",
       "      <td>40</td>\n",
       "      <td>hiiii ! ! question what is the debate on 2moro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627207</th>\n",
       "      <td>my fiends oh what can I say one of them thinks...</td>\n",
       "      <td>male</td>\n",
       "      <td>154</td>\n",
       "      <td>my fiends oh what can i say one of them thinks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523994</th>\n",
       "      <td>Via Mark Kilmer comes this story about Michael...</td>\n",
       "      <td>male</td>\n",
       "      <td>269</td>\n",
       "      <td>via mark kilmer comes this story about michael...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453260</th>\n",
       "      <td>From NetworkWorldFusion: Microsoft to pitch se...</td>\n",
       "      <td>male</td>\n",
       "      <td>176</td>\n",
       "      <td>from networkworldfusion : microsoft to pitch s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482485</th>\n",
       "      <td>Ok, so apparently I tried to type my last blog...</td>\n",
       "      <td>male</td>\n",
       "      <td>275</td>\n",
       "      <td>ok , so apparently i tried to type my last blo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518847</th>\n",
       "      <td>ha,..am headin to china this saturday in the w...</td>\n",
       "      <td>male</td>\n",
       "      <td>67</td>\n",
       "      <td>ha, .. am headin to china this saturday in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121925</th>\n",
       "      <td>\"Traditionally, grades from the final three we...</td>\n",
       "      <td>male</td>\n",
       "      <td>41</td>\n",
       "      <td>\" traditionally , grades from the final three ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396696</th>\n",
       "      <td>Within the past couple of hours a new edition ...</td>\n",
       "      <td>male</td>\n",
       "      <td>283</td>\n",
       "      <td>within the past couple of hours a new edition ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  gender  n_words  \\\n",
       "610399  every latter-day saint should read eugene engl...    male       17   \n",
       "450653  today was bored at school .. mr liew and miss ...    male      126   \n",
       "82433   sorry about that last outburst...lady green's ...    male       54   \n",
       "406991  In the words of Tenacious D...we are but men! ...    male       17   \n",
       "383245  Its Friday the 13th. Is anyone out there super...  female      373   \n",
       "624995  I am a girly girl. Even if I'm 41. I never car...  female       93   \n",
       "462692  The Pros of Being Me 1. My rapier wit 2. My za...  female      106   \n",
       "255647  HIIII!! QUESTION what is the debate on 2morow ...    male       40   \n",
       "627207  my fiends oh what can I say one of them thinks...    male      154   \n",
       "523994  Via Mark Kilmer comes this story about Michael...    male      269   \n",
       "453260  From NetworkWorldFusion: Microsoft to pitch se...    male      176   \n",
       "482485  Ok, so apparently I tried to type my last blog...    male      275   \n",
       "518847  ha,..am headin to china this saturday in the w...    male       67   \n",
       "121925  \"Traditionally, grades from the final three we...    male       41   \n",
       "396696  Within the past couple of hours a new edition ...    male      283   \n",
       "\n",
       "                                                tokenized  \n",
       "610399  every latter - day saint should read eugene en...  \n",
       "450653  today was bored at school .. mr liew and miss ...  \n",
       "82433   sorry about that last outburst ... lady green ...  \n",
       "406991  in the words of tenacious d ... we are but men...  \n",
       "383245  its friday the 13th . is anyone out there supe...  \n",
       "624995  i am a girly girl . even if i 'm 41 . i never ...  \n",
       "462692  the pros of being me 1 . my rapier wit 2 . my ...  \n",
       "255647  hiiii ! ! question what is the debate on 2moro...  \n",
       "627207  my fiends oh what can i say one of them thinks...  \n",
       "523994  via mark kilmer comes this story about michael...  \n",
       "453260  from networkworldfusion : microsoft to pitch s...  \n",
       "482485  ok , so apparently i tried to type my last blo...  \n",
       "518847  ha, .. am headin to china this saturday in the...  \n",
       "121925  \" traditionally , grades from the final three ...  \n",
       "396696  within the past couple of hours a new edition ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_df = pd.read_csv('../../datasets/tokenized/blog_authorship_tokenized.csv', usecols=['text', 'tokenized', 'n_words', 'gender'])\n",
    "init_df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         0\n",
       "gender       0\n",
       "n_words      0\n",
       "tokenized    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22245, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stratify the sample by age group\n",
    "df = init_df.groupby('gender', group_keys=False).apply(lambda x: x.sample(frac=.035))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      11282\n",
       "female    10963\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'female': 0, 'male': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = LabelEncoder()\n",
    "enc.fit(df['gender'])\n",
    "encoded_labels = dict(zip(enc.classes_, enc.transform(enc.classes_))) # will use that in the cm later\n",
    "df['gender'] = enc.transform(df['gender'])\n",
    "encoded_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17796, 1), (4449, 1), (17796,), (4449,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['text']]\n",
    "y = df['gender']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True, random_state=123, stratify=y)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_vect = CountVectorizer()\n",
    "base_ct = ColumnTransformer([('vect', base_vect, 'text')], remainder='drop', n_jobs=-1)\n",
    "base_svm = SVC(kernel='linear')\n",
    "base_pipe = make_pipeline(base_ct, base_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_params = {\n",
    "    'verbose': [5] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END ..........................svc__C=1;, score=0.626 total time=60.6min\n",
      "[CV 2/5] END ..........................svc__C=1;, score=0.610 total time=62.8min\n",
      "[CV 3/5] END ..........................svc__C=1;, score=0.598 total time=66.6min\n",
      "[CV 4/5] END ..........................svc__C=1;, score=0.608 total time=59.7min\n",
      "[CV 5/5] END ..........................svc__C=1;, score=0.590 total time=64.1min\n",
      "[CV 1/5] END .........................svc__C=10;, score=0.623 total time=80.4min\n"
     ]
    }
   ],
   "source": [
    "baseline = GridSearchCV(base_pipe, base_params, cv=5, scoring='f1_macro', refit=True, n_jobs=12)\n",
    "\n",
    "baseline.fit(X_train, y_train)\n",
    "print(baseline.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = baseline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=baseline.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=baseline.classes_)\n",
    "disp.display_labels = encoded_labels\n",
    "disp.plot(cmap='Blues')\n",
    "disp.ax_.tick_params(axis='x', rotation=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On tokenized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['tokenized']]\n",
    "y = df['gender']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True, random_state=123, stratify=y)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_2grams_cv = CountVectorizer(analyzer='char', ngram_range=(2, 2), max_features=4000, stop_words=None)\n",
    "ch_3grams_cv = CountVectorizer(analyzer='char', ngram_range=(3, 3), max_features=4000, stop_words=None)\n",
    "wd_2grams_cv = CountVectorizer(analyzer='word', ngram_range=(2, 2), max_features=4000, stop_words=None)\n",
    "wd_3grams_cv = CountVectorizer(analyzer='word', ngram_range=(2, 2), max_features=4000, stop_words=None)\n",
    "scl = MinMaxScaler()\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('vect_ch_2', ch_2grams_cv, 'tokenized'),\n",
    "    ('vect_ch_3', ch_3grams_cv, 'tokenized'),\n",
    "    # ('vect_wd_2', wd_2grams_cv, 'tokenized'),\n",
    "    ('vect_wd_3', wd_3grams_cv, 'tokenized'),\n",
    "], remainder='passthrough', n_jobs=-1)\n",
    "\n",
    "svm = SVC(kernel='linear')\n",
    "logreg = LogisticRegression(\n",
    "        solver='liblinear',\n",
    "        penalty='l2'\n",
    "    )\n",
    "\n",
    "pipe = make_pipeline(ct, logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'logisticregression__C': [1, 10],\n",
    "    'logisticregression__max_iter': [5000, 2500, 1000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(pipe, param_grid, cv=10, scoring='f1_macro', n_jobs=-1, refit=True, verbose=5, error_score='raise')\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gs.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=gs.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=gs.classes_)\n",
    "disp.display_labels = encoded_labels\n",
    "disp.plot(cmap='Blues')\n",
    "disp.ax_.tick_params(axis='x', rotation=90)\n",
    "disp.ax_.set_facecolor('red');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9104738a4f77f0f2e5f425b4987f9a6e59232ca1dceabd54d576a5c40835aa4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
